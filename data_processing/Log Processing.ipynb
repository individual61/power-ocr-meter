{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2bb412-6fe2-4cdf-85ab-6f978e062b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T19:57:35.454241Z",
     "iopub.status.busy": "2025-09-02T19:57:35.454241Z",
     "iopub.status.idle": "2025-09-02T19:57:36.630918Z",
     "shell.execute_reply": "2025-09-02T19:57:36.630418Z",
     "shell.execute_reply.started": "2025-09-02T19:57:35.454241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32 CSV files; total rows: 234375\n",
      "[Step 1] Applied cutoff at 2025-08-21: kept 230935 / 234375 rows\n",
      "[Step 2] Discarded non-'watt' modes: 3869; rows remaining: 227066\n",
      "[Step 3] Discarded rows where value contains '8888.8000': 0; rows remaining: 227066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_49496\\513810914.py:96: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  err_decode_mask = df[\"error\"].str.contains(r\"(decode|segment|unrecognized|fail|parse)\", case=False, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 4] Discarded rows with decode/segment warnings AND zero/NaN value: 11760; rows remaining: 215306\n",
      "\n",
      "CSV files represented (post-cleaning): 23\n",
      "Segment-decode error rows (remaining): 0 (0.00% of total)\n",
      "Time span: 2025-08-22 16:37:50.372000 → 2025-08-29 15:37:08.748000\n",
      "Total runtime: 6 days, 22 hours, 59 minutes\n"
     ]
    }
   ],
   "source": [
    "# Starter cell: load logs, apply cleaning steps, and report stats\n",
    "# Adjust DATA_DIR if your logs live somewhere else.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Load all CSV logs (read as strings first so we can do exact/substring checks)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "DATA_DIR = Path(\"../data-2025\")\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Data directory not found: {DATA_DIR.resolve()}\")\n",
    "\n",
    "csv_paths = sorted(DATA_DIR.rglob(\"*.csv\"))\n",
    "\n",
    "frames = []\n",
    "expected_cols = [\"timestamp\",\"mode\",\"value\",\"vbat_mV\",\"vin_mV\",\"iout_mA\",\"soc_C\",\"rp1_C\",\"pmic_C\",\"error\"]\n",
    "\n",
    "for p in csv_paths:\n",
    "    try:\n",
    "        tmp = pd.read_csv(p, dtype=str)   # keep everything as str for now\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: failed to read {p}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    for col in expected_cols:\n",
    "        if col not in tmp.columns:\n",
    "            tmp[col] = np.nan\n",
    "\n",
    "    # Preserve raw value string EXACTLY as read (no strip/normalize yet)\n",
    "    tmp[\"value_str\"] = tmp[\"value\"].astype(str)\n",
    "\n",
    "    # Normalize text fields we care about\n",
    "    tmp[\"mode\"]  = tmp[\"mode\"].astype(str).str.strip().str.lower()\n",
    "    tmp[\"error\"] = tmp[\"error\"].astype(str).fillna(\"\").str.strip()\n",
    "\n",
    "    # Parse timestamp\n",
    "    tmp[\"timestamp\"] = pd.to_datetime(tmp[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    # Keep source filename\n",
    "    tmp[\"source_file\"] = str(p)\n",
    "\n",
    "    frames.append(tmp)\n",
    "\n",
    "if frames:\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "else:\n",
    "    df = pd.DataFrame(columns=expected_cols + [\"value_str\",\"source_file\"])\n",
    "\n",
    "print(f\"Loaded {len(csv_paths)} CSV files; total rows: {len(df)}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# STEP 1: Apply cutoff date; report rows remaining\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "CUTOFF_DATE = pd.Timestamp(\"2025-08-21\")  # inclusive: keep rows >= 2025-08-21 00:00\n",
    "before_rows = len(df)\n",
    "df = df[df[\"timestamp\"] >= CUTOFF_DATE].copy()\n",
    "print(f\"[Step 1] Applied cutoff at {CUTOFF_DATE.date()}: kept {len(df)} / {before_rows} rows\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# STEP 2: Keep only rows where mode is exactly \"watt\"; report discarded & remaining\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "pre_rows = len(df)\n",
    "mode_mask = df[\"mode\"].eq(\"watt\")   # exact string match\n",
    "discarded_non_watt = int((~mode_mask).sum())\n",
    "df = df[mode_mask].copy()\n",
    "print(f\"[Step 2] Discarded non-'watt' modes: {discarded_non_watt}; rows remaining: {len(df)}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# STEP 3: Discard rows whose raw 'value' STRING contains \"8888.8000\"\n",
    "#         (substring match; no numeric conversions; resilient to quotes/padding)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "pre_rows = len(df)\n",
    "sentinel_mask = df[\"value_str\"].astype(str).str.contains(\"8888.8000\", regex=False, na=False)\n",
    "discarded_sentinels = int(sentinel_mask.sum())\n",
    "df = df[~sentinel_mask].copy()\n",
    "print(f\"[Step 3] Discarded rows where value contains '8888.8000': {discarded_sentinels}; rows remaining: {len(df)}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# STEP 4: Discard rows with decode/segment warnings *AND* zero/NaN reading\n",
    "#         (e.g., \"Warning: decode_digit got unrecognized segment pattern: ...\")\n",
    "#         This targets bogus zeros without dropping all rows that happen to have warnings.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "pre_rows = len(df)\n",
    "\n",
    "# Build a temporary numeric value for zero/NaN checks (strip commas/whitespace safely)\n",
    "value_norm_for_num = df[\"value_str\"].str.replace(r\"[^\\d.\\-]\", \"\", regex=True)\n",
    "value_num_tmp = pd.to_numeric(value_norm_for_num, errors=\"coerce\")\n",
    "zero_or_nan = value_num_tmp.isna() | value_num_tmp.eq(0)\n",
    "\n",
    "# Error pattern indicating decoding/segment issues\n",
    "err_decode_mask = df[\"error\"].str.contains(r\"(decode|segment|unrecognized|fail|parse)\", case=False, na=False)\n",
    "\n",
    "drop_mask = err_decode_mask & zero_or_nan\n",
    "discarded_err_zero = int(drop_mask.sum())\n",
    "df = df[~drop_mask].copy()\n",
    "print(f\"[Step 4] Discarded rows with decode/segment warnings AND zero/NaN value: {discarded_err_zero}; rows remaining: {len(df)}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Additional summary (post-cleaning)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Convert numerics now that string-based filtering is done\n",
    "for num_col in [\"value\",\"vbat_mV\",\"vin_mV\",\"iout_mA\",\"soc_C\",\"rp1_C\",\"pmic_C\"]:\n",
    "    df[num_col] = pd.to_numeric(df[num_col], errors=\"coerce\")\n",
    "\n",
    "# Decode-error count & percentage (post-cleaning; informational only)\n",
    "pat = re.compile(r\"(?:decode.*digit|segment)\", re.IGNORECASE)\n",
    "decode_err_mask = df[\"error\"].str.contains(pat, na=False)\n",
    "decode_err_rows = int(decode_err_mask.sum())\n",
    "total_rows = len(df)\n",
    "decode_pct = (decode_err_rows / total_rows * 100.0) if total_rows else 0.0\n",
    "\n",
    "# Single total runtime as D/H/M\n",
    "if total_rows and df[\"timestamp\"].notna().any():\n",
    "    tmin = df[\"timestamp\"].min()\n",
    "    tmax = df[\"timestamp\"].max()\n",
    "    span = tmax - tmin\n",
    "    total_seconds = int(span.total_seconds())\n",
    "    days = total_seconds // 86400\n",
    "    rem = total_seconds % 86400\n",
    "    hours = rem // 3600\n",
    "    rem %= 3600\n",
    "    minutes = rem // 60\n",
    "else:\n",
    "    tmin = tmax = None\n",
    "    days = hours = minutes = 0\n",
    "\n",
    "print(f\"\\nCSV files represented (post-cleaning): {df['source_file'].nunique()}\")\n",
    "print(f\"Segment-decode error rows (remaining): {decode_err_rows} ({decode_pct:.2f}% of total)\")\n",
    "print(f\"Time span: {tmin} → {tmax}\")\n",
    "print(f\"Total runtime: {days} days, {hours} hours, {minutes} minutes\")\n",
    "\n",
    "# `df` is now the cleaned DataFrame for plots/analysis.\n",
    "# Example: power_df = df[['timestamp','value','soc_C']].rename(columns={'value':'watts'}).copy()\n",
    "\n",
    "# OPTIONAL (uncomment if you truly never expect 0 W in valid data):\n",
    "# zeros_left = int((df['value'] == 0).sum())\n",
    "# if zeros_left:\n",
    "#     print(f\"Note: {zeros_left} zero-watt rows remain (no decode warning). Uncomment filter below to drop them.\")\n",
    "#     # df = df[df['value'] != 0].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55facdcb-1783-40f3-8884-84c5a337028e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T19:59:08.766390Z",
     "iopub.status.busy": "2025-09-02T19:59:08.766390Z",
     "iopub.status.idle": "2025-09-02T19:59:09.293466Z",
     "shell.execute_reply": "2025-09-02T19:59:09.292966Z",
     "shell.execute_reply.started": "2025-09-02T19:59:08.766390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved power_watts_all_nightshade.png\n"
     ]
    }
   ],
   "source": [
    "# Chart: Watts vs Time (cleaned df) with option to plot ALL data or a SUBSET\n",
    "# - When SUBSET is chosen, prints the relevant rows from df and saves them to CSV\n",
    "# - 2000 x 1000 PNG, daily major ticks (\"Friday 8/29\"), faint hourly grid, night shading\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# ───────────── CONFIG ─────────────\n",
    "PLOT_SCOPE = \"all\" #\"subset\"   # \"all\" or \"subset\"\n",
    "\n",
    "# If PLOT_SCOPE == \"subset\", choose ONE of the following selection styles:\n",
    "\n",
    "# (A) Time window:\n",
    "SUBSET_START = \"2025-08-25 20:30:00\"\n",
    "SUBSET_END   = \"2025-08-25 20:45:00\"\n",
    "\n",
    "# (B) Time around a center point (± minutes):\n",
    "CENTER_TIME  = \"2025-08-25 19:05:00\"\n",
    "RADIUS_MIN   = 10\n",
    "\n",
    "# Selection style to use when PLOT_SCOPE == \"subset\": \"window\" or \"around\"\n",
    "SUBSET_STYLE = \"window\"  # \"window\" or \"around\"\n",
    "\n",
    "# Output / printing controls\n",
    "OUT_PNG = \"power_watts_subset_nightshade.png\" if PLOT_SCOPE == \"subset\" else \"power_watts_all_nightshade.png\"\n",
    "PRINT_MAX_ROWS = 500      # cap printed rows to avoid flooding the console\n",
    "SAVE_SUBSET_CSV = True\n",
    "SUBSET_CSV_PATH = \"subset_rows_for_manual_check.csv\"\n",
    "\n",
    "# Night shading times (fixed for the whole range)\n",
    "SUNRISE_STR = \"06:22:28\"\n",
    "SUNSET_STR  = \"19:31:14\"\n",
    "\n",
    "# Figure size for 2000 x 1000\n",
    "FIGSIZE_IN = (10, 5)\n",
    "DPI = 200\n",
    "# ──────────────────────────────────\n",
    "\n",
    "def _fmt_day(x, pos):\n",
    "    d = mdates.num2date(x)\n",
    "    try:\n",
    "        return d.strftime(\"%A %-m/%-d\")   # POSIX\n",
    "    except ValueError:\n",
    "        return d.strftime(\"%A %#m/%#d\")   # Windows\n",
    "\n",
    "def _select_subset(df):\n",
    "    \"\"\"Return a (dataframe, description) tuple based on SUBSET_STYLE.\"\"\"\n",
    "    if SUBSET_STYLE == \"window\":\n",
    "        lo = pd.Timestamp(SUBSET_START)\n",
    "        hi = pd.Timestamp(SUBSET_END)\n",
    "        m = (df[\"timestamp\"] >= lo) & (df[\"timestamp\"] <= hi)\n",
    "        return df.loc[m].copy(), f\"time window {lo} → {hi}\"\n",
    "    elif SUBSET_STYLE == \"around\":\n",
    "        c = pd.Timestamp(CENTER_TIME)\n",
    "        lo = c - pd.Timedelta(minutes=RADIUS_MIN)\n",
    "        hi = c + pd.Timedelta(minutes=RADIUS_MIN)\n",
    "        m = (df[\"timestamp\"] >= lo) & (df[\"timestamp\"] <= hi)\n",
    "        return df.loc[m].copy(), f\"{RADIUS_MIN} min around {c}  (window {lo} → {hi})\"\n",
    "    else:\n",
    "        raise ValueError(\"SUBSET_STYLE must be 'window' or 'around'\")\n",
    "\n",
    "# Sanity\n",
    "if df.empty:\n",
    "    print(\"Cleaned DataFrame `df` is empty — nothing to plot.\")\n",
    "else:\n",
    "    # Choose data to plot\n",
    "    if PLOT_SCOPE == \"all\":\n",
    "        plot_df = df.copy()\n",
    "        scope_desc = \"ALL cleaned data\"\n",
    "    else:\n",
    "        plot_df, scope_desc = _select_subset(df)\n",
    "        if plot_df.empty:\n",
    "            print(f\"Subset selection produced 0 rows ({scope_desc}). Nothing to plot.\")\n",
    "            # Still show a hint of what's available:\n",
    "            print(\"Data range:\", df['timestamp'].min(), \"→\", df['timestamp'].max(), f\"(rows={len(df)})\")\n",
    "        else:\n",
    "            # Print and save subset rows for manual inspection\n",
    "            cols_to_show = [c for c in [\"timestamp\",\"value\",\"mode\",\"error\",\"source_file\",\"vbat_mV\",\"vin_mV\",\"iout_mA\",\"soc_C\",\"rp1_C\",\"pmic_C\"] if c in plot_df.columns]\n",
    "            print(f\"\\nSubset rows selected ({len(plot_df)} rows) — {scope_desc}\")\n",
    "            if len(plot_df) > PRINT_MAX_ROWS:\n",
    "                print(plot_df[cols_to_show].head(PRINT_MAX_ROWS).to_string(index=False))\n",
    "                print(f\"... ({len(plot_df) - PRINT_MAX_ROWS} more rows not shown)\")\n",
    "            else:\n",
    "                print(plot_df[cols_to_show].to_string(index=False))\n",
    "            if SAVE_SUBSET_CSV:\n",
    "                plot_df.to_csv(SUBSET_CSV_PATH, index=False)\n",
    "                print(f\"Saved subset to CSV: {SUBSET_CSV_PATH}\")\n",
    "\n",
    "    # If nothing to plot, stop here.\n",
    "    if plot_df.empty:\n",
    "        pass\n",
    "    else:\n",
    "        # Ensure sorted and columns present\n",
    "        plot_df = plot_df.sort_values(\"timestamp\")\n",
    "        watts = plot_df[[\"timestamp\",\"value\"]].rename(columns={\"value\":\"watts\"}).dropna()\n",
    "\n",
    "        # Build sunrise/sunset times\n",
    "        sunrise_t = dt.datetime.strptime(SUNRISE_STR, \"%H:%M:%S\").time()\n",
    "        sunset_t  = dt.datetime.strptime(SUNSET_STR,  \"%H:%M:%S\").time()\n",
    "\n",
    "        # Figure & plot\n",
    "        fig = plt.figure(figsize=FIGSIZE_IN, dpi=DPI)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(watts[\"timestamp\"], watts[\"watts\"], linewidth=0.9)\n",
    "        ax.set_ylabel(\"Watts\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_title(f\"Watts vs Time — {scope_desc}\")\n",
    "\n",
    "        # Daily major ticks, hourly minor grid\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(_fmt_day))\n",
    "        ax.xaxis.set_minor_locator(mdates.HourLocator(interval=1))\n",
    "        ax.grid(which=\"minor\", axis=\"x\", linestyle=\"-\", linewidth=0.5, alpha=0.3, color=\"0.8\")\n",
    "\n",
    "        # Night shading (outside sunrise–sunset) clipped to plot_df span\n",
    "        left_data, right_data = watts[\"timestamp\"].min(), watts[\"timestamp\"].max()\n",
    "        day_start = left_data.normalize()\n",
    "        day_end   = (right_data.normalize() + pd.Timedelta(days=1))\n",
    "        current = day_start\n",
    "        while current < day_end:\n",
    "            sr = pd.Timestamp.combine(current, sunrise_t)\n",
    "            ss = pd.Timestamp.combine(current, sunset_t)\n",
    "            l1, r1 = max(current, left_data), min(sr, right_data)                 # [00:00, sunrise)\n",
    "            l2, r2 = max(ss, left_data), min(current + pd.Timedelta(days=1), right_data)  # [sunset, 24:00)\n",
    "            if l1 < r1:\n",
    "                ax.axvspan(l1, r1, alpha=0.08, zorder=0)\n",
    "            if l2 < r2:\n",
    "                ax.axvspan(l2, r2, alpha=0.08, zorder=0)\n",
    "            current += pd.Timedelta(days=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT_PNG, dpi=DPI)\n",
    "        plt.close(fig)\n",
    "        print(f\"\\nSaved {OUT_PNG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4811c16-d05c-4af4-a060-c81120f227cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
